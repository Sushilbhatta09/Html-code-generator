# -*- coding: utf-8 -*-
"""Copy of Minor Project(Automatic Html code Generator using LSTM)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uWo_bx2AU4pnL8VDPc4yGLmo5_Osk2vS
"""

from google.colab import drive
drive.mount('/content/drive')

"""# New Section

# Automatic HTML Code Generator Using LSTM
"""

from os import listdir
import numpy as np
from numpy import array
from keras.preprocessing.image import array_to_img, img_to_array, load_img
from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input

"""### Load the Images from the directory , resizing the image to (299x299) and  changing images to array"""

wireframes=[]

wireframe_files = listdir('/content/drive/MyDrive/Colab Notebooks (1)/Wireframes/')
wireframe_files.sort() 


for wireframe in wireframe_files:
    images_in_array=img_to_array(load_img('/content/drive/MyDrive/Colab Notebooks (1)/Wireframes/'+wireframe,target_size=(299,299)))
    wireframes.append(images_in_array)

    
wireframes = np.array(wireframes,dtype=float)

"""### Preprocessing the wireframe using Inception_resnet_v2 (CNN PART)"""

wireframe = preprocess_input(wireframes)
print(wireframe)
#Transfer learning 
IR2 = InceptionResNetV2(weights='imagenet',include_top=False) 


features = IR2.predict(wireframe)

"""### Load Html File from directory """

from keras.preprocessing.text import Tokenizer, one_hot
from keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical 

# !pip list -v

# import tensorflow
# print(tensorflow.__version__)

htmls = []


def load_doc(filename):
    file = open(filename,'r')
    text = file.read()
    file.close()
    return text


html_files=listdir('/content/drive/MyDrive/Colab Notebooks (1)/HTML/')
html_files.sort()
for html in html_files:
    htmls.append(load_doc('/content/drive/MyDrive/Colab Notebooks (1)/HTML/'+html))

"""### creating the own vocabulary and taking caption length for each input sequence """

max_caption_len=10

# Tokenization of the html code 
tokenizer = Tokenizer(filters='',split=" ",lower=False)

# Create the vocabulary from the html files
tokenizer.fit_on_texts(htmls)


vocab_size = len(tokenizer.word_index)+1

# Translate each word in text file to the matching vocabulary index
sequences = tokenizer.texts_to_sequences(htmls)

# The longest HTML file
max_length = max(len(s) for s in sequences)

# Intialize our final input to the model
X, y, image_data = list(), list(), list()

# tokenizer.index_word

import io
import json
tokenizer_json = tokenizer.to_json()
with io.open('tokenizer.json', 'w', encoding='utf-8') as f:
    f.write(json.dumps(tokenizer_json, ensure_ascii=False))

for img_no,seq in enumerate(sequences):
    for i in range (1, len(seq)):
        in_seq,out_seq=seq[:i],seq[i]
        in_seq = pad_sequences([in_seq],maxlen=max_length)[0]
        out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
        image_data.append(features[img_no])
        X.append(in_seq[-10:])
        y.append(out_seq)

X,y,image_data = np.array(X),np.array(y),np.array(image_data)

"""## Creating the model """

from keras.layers import Embedding, TimeDistributed, RepeatVector, LSTM, concatenate , Input, Reshape, Dense, Flatten
from keras.models import Model

"""### creating the encoder """

image_features = Input(shape=(8,8,1536,))
image_flat = Flatten()(image_features)
image_flat = Dense(128, activation='relu')(image_flat)
ir2_out = RepeatVector(max_caption_len)(image_flat)

language_input = Input(shape=(max_caption_len,))
language_model = Embedding(vocab_size, 200, input_length=max_caption_len)(language_input)
language_model = LSTM(256, return_sequences=True)(language_model)
language_model = LSTM(256, return_sequences=True)(language_model)
language_model = TimeDistributed(Dense(128, activation='relu'))(language_model)

"""### creating the decoder"""

decoder = concatenate([ir2_out, language_model])
decoder = LSTM(512, return_sequences=False)(decoder)
decoder_output = Dense(vocab_size, activation='softmax')(decoder)

"""### compile the model"""

model = Model(inputs=[image_features, language_input], outputs=decoder_output)
model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])

"""### Train the neural network"""

model.fit([image_data, X], y, batch_size=140, shuffle=False, epochs=40)

"""# MODEL SAVED"""

model.save('/content/drive/MyDrive/Colab Notebooks (1)/my_model5.h5')

from tensorflow.keras.models import load_model
model1 = load_model('/content/drive/MyDrive/Colab Notebooks (1)/my_model5.h5')

"""**OUTPUT**"""



# map an integer to a word
def word_for_id(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

# generate a description for an image
def generate_desc(model1, tokenizer, photo, max_length):
    # seed the generation process
    in_text = 'START'
    # iterate over the whole length of the sequence
    for i in range(1000):
        # integer encode input sequence
        sequence = tokenizer.texts_to_sequences([in_text])[0][-10:]
        
        # pad input
        sequence = pad_sequences([sequence], maxlen=max_length)
       
        # predict next word
        yhat = model1.predict([photo,sequence], verbose=0)
        
        # convert probability to integer
        yhat = np.argmax(yhat)
       
        # map integer to word
        word = word_for_id(yhat, tokenizer)
      
        # stop if we cannot map the word
        if word is None:
            break
        # append as input for generating the next word
        in_text += ' ' + word
        # Print the prediction
        print(' '+word, end='')
        # stop if we predict the end of the sequence
        if word == '\n</html>':
            break
    return

# Load and image, preprocess it for IR2, extract features and generate the HTML
test_image = img_to_array(load_img('/content/drive/MyDrive/Colab Notebooks (1)/test.jpg', target_size=(299, 299)))
test_image = np.array(test_image, dtype=float)
test_image = preprocess_input(test_image)
test_features = IR2.predict(np.array([test_image]))
generate_desc(model1, tokenizer, np.array(test_features), 10)